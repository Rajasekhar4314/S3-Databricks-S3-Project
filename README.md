# S3-Databricks-S3

Step1: Dowloaded the data from kaggle and upload the very same data to AWS S3.
Step2: Create a User account and provide access S3 Full access to the User which we have created. Also Download Access Key there.
Step3: Open Databricks Community Edition for Transformation analysis and Connect with S3 Using AWS Access Key and Secret Key.
Step4: Perform any Operations for Business Use cases and Write the Transformed Data to the S3 in CSV Format.
Step5: Check the Data is Written in S3 or Not.
Step6: And Finally, UnMount The AWS S3 Bucket, So that No Discrepancy will Occur Between these Databricks and AWS S3.


-----------------------------------Thank You------------------------------------------------------------
